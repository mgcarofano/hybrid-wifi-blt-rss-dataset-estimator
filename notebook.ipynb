{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Hybrid WiFi/Bluetooth RSS Dataset with LS-based localization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(anchors, directory_path):\n",
    "    \"\"\"\n",
    "    Reads the csv-files for one specified measurement case and adds them into a dict of dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    anchors (list): List of anchors, for example [\"Anchor 1\", \"Anchor 2\", \"Anchor 3\"...]\n",
    "    directory path (string): The relative directory path of the folder which contains the wanted anchor-csv.files.\n",
    "\n",
    "    returns: \n",
    "    scenario_dataframes (dict): a dict which keys are the anchor names and values are the respective dataframes.\n",
    "    \"\"\"\n",
    "    scenario_dataframes = {}\n",
    "\n",
    "    for anchor in anchors:\n",
    "        current_df = pd.read_csv(directory_path + anchor + \".csv\", sep=';')\n",
    "        scenario_dataframes[anchor.replace(\".csv\",\"\")] = current_df\n",
    "    \n",
    "    return scenario_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smallest_dataset(dataframes):\n",
    "    \"\"\"\n",
    "    Calculates the minimum over all dataframes' length.\n",
    "\n",
    "    Parameters:\n",
    "    dataframes (dict): a dict which keys are the anchor names and values are the respective dataframes.\n",
    "\n",
    "    Returns:\n",
    "    minimum_length (int): an integer which value represents the minimum over all dataframes' length.\n",
    "    \"\"\"\n",
    "\n",
    "    sizes = []\n",
    "\n",
    "    for anchor in dataframes:\n",
    "        df = dataframes[anchor]\n",
    "        sizes.append(len(df))\n",
    "\n",
    "    return min(sizes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_burst_quantity(length, burst_size):\n",
    "    \"\"\"\n",
    "    Calculates the amount of bursts over all dataframes.\n",
    "\n",
    "    Parameters:\n",
    "    burst_size (int): An integer which value represents the size of a burst, e.g. the number of consecutive samples.\n",
    "    length (int): An integer which value represents the number of data to read in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    bursts (int): An integer which value represents the amount of bursts / configurations.\n",
    "    \"\"\"\n",
    "\n",
    "    bursts = length // burst_size\n",
    "    end = burst_size * bursts\n",
    "\n",
    "    if (end < length):\n",
    "        bursts = bursts + 1\n",
    "    \n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_target_anchors_distance(dataframes):\n",
    "    \"\"\"\n",
    "    Calculates the distance between the target and the anchors using the Euclidean norm.\n",
    "    This is the implementation of (1) on the reference paper.\n",
    "\n",
    "    Parameters:\n",
    "    dataframes (dict): a dict which keys are the anchor names and values are the respective dataframes.\n",
    "\n",
    "    Returns:\n",
    "    target_anchors_distance (list): Returns a list of distances between the target and the anchor.\n",
    "    \"\"\"\n",
    "\n",
    "    target_anchors_distance = []\n",
    "\n",
    "    for anchor in dataframes:\n",
    "        df = dataframes[anchor]\n",
    "        anchor_coords = [eval(i) for i in df[\"Relative Coordinates [m]\"][0].split(\", \")]\n",
    "        target_coords = [eval(i) for i in df[\"Target Coordinates [m]\"][0].split(\", \")]\n",
    "        target_anchors_distance.append(math.dist(anchor_coords, target_coords))\n",
    "\n",
    "    # print(target_anchors_distance)\n",
    "    return target_anchors_distance\n",
    "\n",
    "# LINKS\n",
    "# https://www.w3schools.com/python/ref_math_dist.asp\n",
    "# https://www.w3schools.com/python/ref_string_split.asp\n",
    "# https://www.geeksforgeeks.org/python-converting-all-strings-in-list-to-integers/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_values(scenario_dataframe, length, burst_size): \n",
    "    \"\"\"\n",
    "    Calculates the mean value over a given amount of bursts.\n",
    "    This is the implementation of (3) on the reference paper.\n",
    "\n",
    "    Parameters:\n",
    "    scenario_dataframe (DataFrame): A DataFrame-object containing the dataset of one anchor.\n",
    "    length (int): An integer which value represents the number of data to read in the dataset.\n",
    "    burst_size (int): An integer which value represents the size of a burst, e.g. the number of consecutive samples.\n",
    "\n",
    "    Returns:\n",
    "    mean_values (list): Returns a list of mean values over the given amount of bursts.\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_values = []\n",
    "    power_values = scenario_dataframe[\"Rx Power [dBm]\"].to_list()\n",
    "    bursts = calculate_burst_quantity(length, burst_size)\n",
    "\n",
    "    start = 0\n",
    "    for i in range(bursts):\n",
    "        end = start + burst_size\n",
    "        # print(\"start: \", start)\n",
    "        if (end <= length):\n",
    "            # print(\"end: \", end)\n",
    "            mean_values.append(round(np.mean(power_values[start:end]), 3))\n",
    "        else:\n",
    "            # print(\"end: \", length)\n",
    "            mean_values.append(round(np.mean(power_values[start:length]), 3))\n",
    "        start = end\n",
    "\n",
    "    return mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_anchors_estimation(reference_power, path_loss_exp, mean_values):\n",
    "    \"\"\"\n",
    "    Calculates the distance estimates between each anchor and the target.\n",
    "    This is the implementation of (4) on the reference paper.\n",
    "\n",
    "    Parameters:\n",
    "    reference_power (int): The initial RSS value for the distance estimation equation.\n",
    "    path_loss_exp (int): The \"path loss exponent\" for the distance estimation formula.\n",
    "    mean_values (list): A list which values are mean values over the given amount of bursts.\n",
    "\n",
    "    Returns:\n",
    "    estimated_distances (list): Returns a list which values are the distance estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    estimated_distances = []\n",
    "    index = 0\n",
    "    \n",
    "    for mean in mean_values:\n",
    "        num = mean - reference_power\n",
    "        den = -10 * path_loss_exp\n",
    "        estimated_distances.append(round(10**(num/den), 3))\n",
    "        index = index + 1\n",
    "\n",
    "    return estimated_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_A_matrix(anchor_coordinates):\n",
    "    anchors = list(anchor_coordinates.keys())\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    # Build matrix A\n",
    "    A = np.zeros((num_anchors, 3))  # 3 columns for -2x, -2y, 1\n",
    "\n",
    "    for i, anchor in enumerate(anchors):\n",
    "        A[i, 0] = -2 * anchor_coordinates[anchor][0]\n",
    "        A[i, 1] = -2 * anchor_coordinates[anchor][1]\n",
    "        A[i, 2] = 1\n",
    "        \n",
    "    print(\"Matrix A:\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_b_vector(n_anchors, configuration):\n",
    "    \"\"\"\n",
    "    Calculates the 'b' vector of the system of equations which the WLS method solves.\n",
    "    This is the implementation of (5) on the reference paper.\n",
    "\n",
    "    Parameters:\n",
    "    n_anchors (int): An integer which value represents the number of anchors in dataset.\n",
    "    configuration (dict): A dict which keys are the anchor names and values are the respective configurations.\n",
    "\n",
    "    Returns:\n",
    "    b (numpy.array): Returns a 1D numpy.array which values are elements of the 'b' vector for the selected configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # A list containing one real number for each anchor.\n",
    "    # That value is the distance estimation between each anchor and the target.\n",
    "    local_estimated_distances = configuration[\"Estimated Distance\"]\n",
    "    \n",
    "    # A list containing one list for each anchor.\n",
    "    # Those lists are the 2D-coordinates of each anchor.\n",
    "    local_anchor_coords = configuration[\"Coordinates\"]\n",
    "    norm_coords = []\n",
    "\n",
    "    b = []\n",
    "\n",
    "    for i in range(n_anchors):\n",
    "        # print(local_estimated_distances[i])\n",
    "        sqr_distance = math.pow(local_estimated_distances[i], 2)\n",
    "        norm_coords.append(np.linalg.norm(local_anchor_coords))\n",
    "        sqr_coords = math.pow(norm_coords[i], 2)\n",
    "        diff = sqr_distance - sqr_coords\n",
    "        b.append(round(diff, 3))\n",
    "        i = i + 1\n",
    "    \n",
    "    return np.array(b)\n",
    "\n",
    "# https://www.digitalocean.com/community/tutorials/norm-of-vector-python\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.append.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_W_matrix(n_anchors, path_loss_exp, configuration):\n",
    "    \"\"\"\n",
    "    Calculates, for the selected configuration, the 'W' diagonal matrix.\n",
    "    The elements are the inverse of the variance of the square of the estimated distance.\n",
    "    This is the implementation of [11, eq. (14)].\n",
    "\n",
    "    Parameters:\n",
    "    n_anchors (int): An integer which value represents the number of anchors in dataset.\n",
    "    configuration (dict): A dict which keys are the anchor names and values are the respective configurations.\n",
    "\n",
    "    Returns:\n",
    "    W (numpy.array): Returns a 2D numpy.array which values are elements of the 'W' diagonal matrix for the selected configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    # A list containing one real number for each anchor.\n",
    "    # That value is the distance estimation between each anchor and the target.\n",
    "    local_estimated_distances = configuration[\"Estimated Distance\"]\n",
    "\n",
    "    standard_deviation = 2\n",
    "    num = math.pow(standard_deviation, 2)\n",
    "    den = 4.715 * math.pow(path_loss_exp, 2)\n",
    "    exp_value = math.exp(num/den)\n",
    "    var_inverse = []\n",
    "\n",
    "    for i in range(n_anchors):\n",
    "        e4_distance = math.pow(local_estimated_distances[i], 4)\n",
    "        var = e4_distance * exp_value * (exp_value-1)\n",
    "        var_inverse.append(round(math.pow(var, -1), 3))\n",
    "\n",
    "    return np.diag(var_inverse)\n",
    "    \n",
    "# https://www.w3schools.com/python/ref_math_exp.asp\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.diag.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WLS_output(A, W, b):\n",
    "    \"\"\"\n",
    "    Calculate the Weighted Least Squares (WLS) position estimate.\n",
    "\n",
    "    Parameters:\n",
    "    - A (numpy.ndarray): Matrix A.\n",
    "    - W (numpy.ndarray): Weight matrix W.\n",
    "    - b (numpy.ndarray): Vector b.\n",
    "\n",
    "    Returns:\n",
    "    - position (numpy.ndarray): WLS position estimate.\n",
    "    \"\"\"\n",
    "    A_transpose = np.transpose(A)\n",
    "    \n",
    "    # Calculate (A^T * W * A)^(-1) * A^T * W * b\n",
    "    left_term = np.linalg.inv(np.matmul(np.matmul(A_transpose, W), A))\n",
    "    right_term = np.matmul(np.matmul(A_transpose, W), b)\n",
    "\n",
    "    # Calculate the final result\n",
    "    position = np.matmul(left_term, right_term)\n",
    "\n",
    "    return position\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.matmul.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculate_mean_values() missing 1 required positional argument: 'burst_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m actual_distances \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anchor \u001b[38;5;129;01min\u001b[39;00m dataframes:\n\u001b[0;32m---> 26\u001b[0m     mean_values[anchor] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mean_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburst_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(anchor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean value over\u001b[39m\u001b[38;5;124m\"\u001b[39m, burst_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbursts:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_values[anchor])\n\u001b[1;32m     30\u001b[0m configurations \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mTypeError\u001b[0m: calculate_mean_values() missing 1 required positional argument: 'burst_size'"
     ]
    }
   ],
   "source": [
    "directory_path = \"HybridDataset_for_RSSbasedLocalization-main/Scenario A/RPI/RSS_BLT_Dataset/\"\n",
    "anchors = [\"Anchor 1\", \"Anchor 2\", \"Anchor 3\", \"Anchor 4\", \"Anchor 5\", \"Anchor 6\"]\n",
    "dataframes = read_data(anchors, directory_path)\n",
    "length = calculate_smallest_dataset(dataframes)\n",
    "\n",
    "burst_size = 10\n",
    "burst_quantity = calculate_burst_quantity(length, burst_size)\n",
    "n_anchors = len(anchors)\n",
    "reference_power = -40\n",
    "path_loss_exp = 4\n",
    "\n",
    "# print(\"length: \", length, \", burst_quantity: \", burst_quantity, \", burst_size: \", burst_size)\n",
    "\n",
    "# print(\"--- \", anchor, \" ---\")\n",
    "# print(\"\")\n",
    "# print(\"Mean values: \", mean_values[anchor])\n",
    "# print(\"\")\n",
    "# print(\"Estimated distances:\", estimated_distances[anchor])\n",
    "# print(\"\")\n",
    "# print(\"-----\")\n",
    "# print(\"\")\n",
    "\n",
    "mean_values = {}\n",
    "for anchor in dataframes:\n",
    "    mean_values[anchor] = calculate_mean_values(dataframes[anchor], burst_size)\n",
    "    print(anchor, \"mean value over\", burst_size, \"bursts:\", mean_values[anchor])\n",
    "\n",
    "\n",
    "configurations = {}\n",
    "\n",
    "for index in range(burst_quantity):\n",
    "    configurations[index] = {}\n",
    "    configurations[index][\"Mean Power\"] = []\n",
    "    configurations[index][\"Estimated Distance\"] = []\n",
    "    configurations[index][\"Actual Distance\"] = []\n",
    "    configurations[index][\"Coordinates\"] = []\n",
    "    for anchor in dataframes:\n",
    "        configurations[index][\"Mean Power\"].append(mean_values[anchor][index])\n",
    "        configurations[index][\"Estimated Distance\"].append(calculate_target_anchors_estimation(reference_power, path_loss_exp, mean_values[anchor]))\n",
    "        configurations[index][\"Actual Distance\"].append(dataframes[anchor][\"Distance Target - Anchor [m]\"][0])\n",
    "        configurations[index][\"Coordinates\"].append([eval(i) for i in dataframes[anchor][\"Relative Coordinates [m]\"][0].split(\", \")])\n",
    "\n",
    "for index in range(burst_quantity):\n",
    "    pass\n",
    "    # configurations[index][\"B vector\"] = []\n",
    "    # configurations[index][\"W matrix\"] = []\n",
    "    # configurations[index][\"B vector\"].append(calculate_b_vector(n_anchors, configurations[index]))\n",
    "    # configurations[index][\"W matrix\"].append(calculate_W_matrix(n_anchors, path_loss_exp, configurations[index]))\n",
    "\n",
    "pprint.pprint(configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9de1696fcdaf364179ab690f77d22ede36360c9c19fea9a1e8c11e7d63264b22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
