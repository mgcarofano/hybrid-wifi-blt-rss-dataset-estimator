{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLLS_I_estimator.ipynb\n",
    "- Siep Dokter\n",
    "- Emil Jousimaa\n",
    "- Oleksandr Sosovskyy\n",
    "- Mario Gabriele Carofano\n",
    "\n",
    "> This file contains the implementation of 2 alternative WLLS estimators, named OS-WLLS_I (One Step) and TS-WLLS_I (Two Step), as requested in the 4th task, used for estimate the Target Coordinates starting from the RSS information coming from the anchors.\n",
    "\n",
    "> In addition, at the end of file, there are also plots showing the actual position of the target and the anchors, and the estimated position of the target obtained from the execution of the 2 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import import_ipynb\n",
    "import constants\n",
    "import auxfunc\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_AI_matrix(anchor_coords):\n",
    "\t'''\n",
    "\tCalculates the 'AI' matrix of the system of equations [R2, eq. (9)] which the WLLS_I method solves.\n",
    "\tThis is the implementation of [R2, eq. (10)].\n",
    "\n",
    "\tParameters:\n",
    "\tanchor_coords (list) : A list containing one list for each anchor, e.g. the 2D-coordinates of each anchor.\n",
    "\n",
    "\tReturns:\n",
    "\tReturns a 2D numpy.ndarray which values\n",
    "\tare elements of the 'AI' matrix for the selected scenario.\n",
    "\t'''\n",
    "\n",
    "\tn_anchors = len(anchor_coords)\n",
    "\tA = np.zeros((n_anchors, 3))\n",
    "\n",
    "\tfor i in range(n_anchors):\n",
    "\t\tA[i, 0] = -2 * anchor_coords[i][0]\n",
    "\t\tA[i, 1] = -2 * anchor_coords[i][1]\n",
    "\t\tA[i, 2] = 1\n",
    "\n",
    "\treturn A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bI_vector(anchor_coords, estimated_distances):\n",
    "\t'''\n",
    "\tCalculates the 'bI' vector of the system of equations [R2, eq. (9)] which the WLS method solves.\n",
    "\tThis is the implementation of [R2, eq. (10)].\n",
    "\n",
    "\tParameters:\n",
    "\tanchor_coords (list) : A list containing one list for each anchor, e.g. the 2D-coordinates of each anchor.\n",
    "\testimated_distances (list):\n",
    "\tA list containing one real number for each anchor,\n",
    "\te.g. the distance estimation between each anchor and the target.\n",
    "\n",
    "\tReturns:\n",
    "\tReturns a 1D numpy.ndarray which values\n",
    "\tare elements of the 'bII' vector for the selected configuration.\n",
    "\t'''\n",
    "\n",
    "\tn_anchors = len(anchor_coords)\n",
    "\tb = []\n",
    "\n",
    "\tfor i in range(n_anchors):\n",
    "\t\tsqr_distance = math.pow(estimated_distances[i], 2)\n",
    "\t\tsqr_x = math.pow(anchor_coords[i][0], 2)\n",
    "\t\tsqr_y = math.pow(anchor_coords[i][1], 2)\n",
    "\t\tb.append(sqr_distance - sqr_x - sqr_y)\n",
    "\t\ti = i + 1\n",
    "\t\n",
    "\treturn np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CI_matrix(estimated_distances):\n",
    "\t'''\n",
    "\tCalculates, for the selected configuration, the 'CI' diagonal matrix.\n",
    "\tThis is the implementation of [R2, eq. (18)].\n",
    "\n",
    "\tParameters:\n",
    "\testimated_distances (list):\n",
    "\tA list containing one real number for each anchor,\n",
    "\te.g. the distance estimation between each anchor and the target.\n",
    "\n",
    "\tReturns:\n",
    "    Returns a 2D numpy.ndarray which values are elements\n",
    "    of the 'CI' covariance diagonal matrix for the selected configuration.\n",
    "\t'''\n",
    "\n",
    "\tcovariance = []\n",
    "\tvariance = math.pow(constants.STANDARD_DEVIATION, 2)\n",
    "\n",
    "\tfor d in estimated_distances:\n",
    "\t\tsqr_distance = math.pow(d, 2)\n",
    "\t\tcovariance.append(variance * sqr_distance)\n",
    "\t\n",
    "\treturn 4 * np.diag(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Lambda_WLLS_matrix(AI, bI, CI):\n",
    "\t'''\n",
    "\tCalculates the Weighted Linear Least Squares (WLLS) position estimate.\n",
    "\tThis is the implementation of [R2, eq. (18)].\n",
    "\n",
    "\tParameters:\n",
    "\tAI (numpy.ndarray): Matrix AI.\n",
    "\tbI (numpy.ndarray): Vector bI.\n",
    "\tCI (numpy.ndarray): Weight matrix CI.\n",
    "\n",
    "\tReturns:\n",
    "\tReturns the OS_WLLS_I position estimate.\n",
    "\t'''\n",
    "\n",
    "\tAI_transpose = np.transpose(AI)\n",
    "\tCI_inverse = np.linalg.inv(CI)\n",
    "\t\n",
    "\tleft_term = np.linalg.inv(np.matmul(np.matmul(AI_transpose, CI_inverse), AI))\n",
    "\tright_term = np.matmul(np.matmul(AI_transpose, CI_inverse), bI)\n",
    "\n",
    "\treturn np.matmul(left_term, right_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    if x < 0:\n",
    "        return -1\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "# https://www.cuemath.com/algebra/signum-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h_vector(Lambda_WLLS):\n",
    "\t'''\n",
    "\t\n",
    "\t'''\n",
    "\n",
    "\th = []\n",
    "\n",
    "\th.append(math.pow(Lambda_WLLS[0], 2))\n",
    "\th.append(math.pow(Lambda_WLLS[1], 2))\n",
    "\th.append(Lambda_WLLS[2])\n",
    "\n",
    "\treturn np.transpose(np.array(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_K_matrix(Lambda_WLLS):\n",
    "\t'''\n",
    "\t\n",
    "\t'''\n",
    "\n",
    "\tK = []\n",
    "\n",
    "\tK.append(2 * Lambda_WLLS[0])\n",
    "\tK.append(2 * Lambda_WLLS[1])\n",
    "\tK.append(1)\n",
    "\n",
    "\treturn np.diag(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Phi_matrix(K, AI, CI):\n",
    "\t'''\n",
    "\t\n",
    "\t'''\n",
    "\n",
    "\tAI_transpose = np.transpose(AI)\n",
    "\tCI_inverse = np.linalg.inv(CI)\n",
    "\tmid_term = np.linalg.inv(np.matmul(np.matmul(AI_transpose, CI_inverse), AI))\n",
    "\n",
    "\treturn np.matmul(np.matmul(K, mid_term), K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_G_matrix():\n",
    "\t'''\n",
    "\t\n",
    "\t'''\n",
    "\n",
    "\tG = np.zeros((3, 2))\n",
    "\n",
    "\tG[0, 0] = 1\n",
    "\tG[1, 0] = 0\n",
    "\tG[2, 0] = 1\n",
    "\n",
    "\tG[0, 1] = 0\n",
    "\tG[1, 1] = 1\n",
    "\tG[2, 1] = 1\n",
    "\n",
    "\treturn G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_vector(G, Phi, h):\n",
    "\t'''\n",
    "\t\n",
    "\t'''\n",
    "\n",
    "\tG_transpose = np.transpose(G)\n",
    "\tPhi_inverse = np.linalg.inv(Phi)\n",
    "\tleft_term = np.linalg.inv(np.matmul(np.matmul(G_transpose, Phi_inverse), G))\n",
    "\tright_term = np.matmul(np.matmul(G_transpose, Phi_inverse), h)\n",
    "\n",
    "\treturn np.matmul(left_term, right_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TS_WLLS_I_output(Lambda_WLLS, z):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "    p = []\n",
    "\n",
    "    p.append(sgn(Lambda_WLLS[0]) * math.sqrt(z[0]))\n",
    "    p.append(sgn(Lambda_WLLS[1]) * math.sqrt(z[1]))\n",
    "\n",
    "    return np.array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_OS_WLLS_I_estimator(scenario_name):\n",
    "\t'''\n",
    "\tApplies the OS_WLLS_I estimator, as shown in [R2] and in [R2, ref. [6]].\n",
    "\tIt is used for estimate the target's position from the anchors' position.\n",
    "\n",
    "\tParameters:\n",
    "\tscenario_name (str): The name of the scenario to be examined.\n",
    "\n",
    "\tReturns:\n",
    "\tdata (dict):\n",
    "\tIt is a dictionary containing all the salient information retrieved\n",
    "\tfrom the reading of the dataset (Actual) and from the application of the WLS estimator (Estimated),\n",
    "\tfor all types of devices (Arduino, RPI) and for all technology (WiFi, BLT, Hybrid).\n",
    "\t'''\n",
    "\t\n",
    "\tdataset = auxfunc.define_dataset(scenario_name)\n",
    "\n",
    "\tfor type in dataset[scenario_name]:\n",
    "\n",
    "\t\tdict = dataset[scenario_name][type]\n",
    "\t\ttype_path = constants.DATASET_DIRECTORY + scenario_name + \"/\" + type + \"/\"\n",
    "\n",
    "\t\tfor tech in dict:\n",
    "\t\t\tdataframes = []\n",
    "\t\t\tif tech != constants.HYBRID_TECHNOLOGY:\n",
    "\t\t\t\tfor a in dict[tech][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + tech + \"/\" + a\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Concatenates the blt and wifi estimations\n",
    "\t\t\t\tfor b in dict[constants.BLT_TECHNOLOGY][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + constants.BLT_TECHNOLOGY + \"/\" + b\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\n",
    "\t\t\t\tfor w in dict[constants.WIFI_TECHNOLOGY][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + constants.WIFI_TECHNOLOGY + \"/\" + w\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\t\t\t\n",
    "\t\t\tdict[tech][\"Actual\"][\"Dataframes\"] = dataframes\n",
    "\n",
    "\t\tfor tech in dict:\n",
    "\t\t\tdataframes = dict[tech][\"Actual\"][\"Dataframes\"]\n",
    "\t\t\tlength = auxfunc.calculate_smallest_dataset(dataframes)\n",
    "\t\t\tburst_quantity = auxfunc.calculate_burst_quantity(length)\n",
    "\t\t\tn_anchors = len(dict[tech][\"Actual\"][\"Anchors' Name\"])\n",
    "\n",
    "\t\t\t# print(type, tech, length, burst_quantity, n_anchors, len(dataframes))\n",
    "\n",
    "\t\t\tdict[tech][\"Actual\"][\"Distance Target - Anchor\"] = []\n",
    "\t\t\tdict[tech][\"Actual\"][\"Anchor Coordinates\"] = []\n",
    "\t\t\tfor a in range(n_anchors):\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Distance Target - Anchor\"].append(dataframes[a][\"Distance Target - Anchor [m]\"][0])\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Target Coordinates\"] = [eval(i) for i in dataframes[a][\"Target Coordinates [m]\"][0].split(\", \")]\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Anchor Coordinates\"].append([eval(i) for i in dataframes[a][\"Relative Coordinates [m]\"][0].split(\", \")])\n",
    "\n",
    "\t\t\tfor c in range(burst_quantity):\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c] = {}\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Average RSS\"] = []\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"] = []\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor a in range(n_anchors):\n",
    "\t\t\t\t\taverage_RSS = auxfunc.calculate_average_RSS(dataframes[a][\"Rx Power [dBm]\"].to_list(), c, length)\n",
    "\t\t\t\t\testimated_distance = auxfunc.calculate_target_anchor_estimation(average_RSS)\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Average RSS\"].append(average_RSS)\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"].append(estimated_distance)\n",
    "\n",
    "\t\t\t\tAI = calculate_AI_matrix(dict[tech][\"Actual\"][\"Anchor Coordinates\"])\n",
    "\t\t\t\tbI = calculate_bI_vector(dict[tech][\"Actual\"][\"Anchor Coordinates\"], dict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"])\n",
    "\t\t\t\tCI = calculate_CI_matrix(dict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"])\n",
    "\t\t\t\t\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"AI matrix\"] = AI\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"bI vector\"] = bI\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"CI matrix\"] = CI\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Target Coordinates\"] = calculate_Lambda_WLLS_matrix(AI, bI, CI)[[0,1]]\n",
    "\t\t\t\n",
    "\t\t\tdataset[scenario_name][type][tech] = dict[tech]\n",
    "\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_TS_WLLS_I_estimator(scenario_name):\n",
    "\t'''\n",
    "\tApplies the TS_WLLS_I estimator, as shown in [R2] and in [R2, ref. [16]].\n",
    "\tIt is used for estimate the target's position from the anchors' position.\n",
    "\n",
    "\tParameters:\n",
    "\tscenario_name (str): The name of the scenario to be examined.\n",
    "\n",
    "\tReturns:\n",
    "\tdata (dict):\n",
    "\tIt is a dictionary containing all the salient information retrieved\n",
    "\tfrom the reading of the dataset (Actual) and from the application of the WLS estimator (Estimated),\n",
    "\tfor all types of devices (Arduino, RPI) and for all technology (WiFi, BLT, Hybrid).\n",
    "\t'''\n",
    "\t\n",
    "\tdataset = auxfunc.define_dataset(scenario_name)\n",
    "\n",
    "\tfor type in dataset[scenario_name]:\n",
    "\n",
    "\t\tdict = dataset[scenario_name][type]\n",
    "\t\ttype_path = constants.DATASET_DIRECTORY + scenario_name + \"/\" + type + \"/\"\n",
    "\n",
    "\t\tfor tech in dict:\n",
    "\t\t\tdataframes = []\n",
    "\t\t\tif tech != constants.HYBRID_TECHNOLOGY:\n",
    "\t\t\t\tfor a in dict[tech][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + tech + \"/\" + a\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Concatenates the blt and wifi estimations\n",
    "\t\t\t\tfor b in dict[constants.BLT_TECHNOLOGY][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + constants.BLT_TECHNOLOGY + \"/\" + b\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\n",
    "\t\t\t\tfor w in dict[constants.WIFI_TECHNOLOGY][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + constants.WIFI_TECHNOLOGY + \"/\" + w\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\t\t\t\n",
    "\t\t\tdict[tech][\"Actual\"][\"Dataframes\"] = dataframes\n",
    "\n",
    "\t\tfor tech in dict:\n",
    "\t\t\tdataframes = dict[tech][\"Actual\"][\"Dataframes\"]\n",
    "\t\t\tlength = auxfunc.calculate_smallest_dataset(dataframes)\n",
    "\t\t\tburst_quantity = auxfunc.calculate_burst_quantity(length)\n",
    "\t\t\tn_anchors = len(dict[tech][\"Actual\"][\"Anchors' Name\"])\n",
    "\n",
    "\t\t\t# print(type, tech, length, burst_quantity, n_anchors, len(dataframes))\n",
    "\n",
    "\t\t\tdict[tech][\"Actual\"][\"Distance Target - Anchor\"] = []\n",
    "\t\t\tdict[tech][\"Actual\"][\"Anchor Coordinates\"] = []\n",
    "\t\t\tfor a in range(n_anchors):\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Distance Target - Anchor\"].append(dataframes[a][\"Distance Target - Anchor [m]\"][0])\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Target Coordinates\"] = [eval(i) for i in dataframes[a][\"Target Coordinates [m]\"][0].split(\", \")]\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Anchor Coordinates\"].append([eval(i) for i in dataframes[a][\"Relative Coordinates [m]\"][0].split(\", \")])\n",
    "\n",
    "\t\t\tfor c in range(burst_quantity):\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c] = {}\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Average RSS\"] = []\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"] = []\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor a in range(n_anchors):\n",
    "\t\t\t\t\taverage_RSS = auxfunc.calculate_average_RSS(dataframes[a][\"Rx Power [dBm]\"].to_list(), c, length)\n",
    "\t\t\t\t\testimated_distance = auxfunc.calculate_target_anchor_estimation(average_RSS)\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Average RSS\"].append(average_RSS)\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"].append(estimated_distance)\n",
    "\t\t\t\t\t# print(scenario_name, type, tech, c, a)\n",
    "\t\t\t\t\t# print(average_RSS, estimated_distance, dict[tech][\"Actual\"][\"Distance Target - Anchor\"][a])\n",
    "\n",
    "\t\t\t\tAI = calculate_AI_matrix(dict[tech][\"Actual\"][\"Anchor Coordinates\"])\n",
    "\t\t\t\tbI = calculate_bI_vector(dict[tech][\"Actual\"][\"Anchor Coordinates\"], dict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"])\n",
    "\t\t\t\tCI = calculate_CI_matrix(dict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"])\n",
    "\t\t\t\tLambda_WLLS = calculate_Lambda_WLLS_matrix(AI, bI, CI)\n",
    "\n",
    "\t\t\t\t# print(Lambda_WLLS[0], Lambda_WLLS[1], Lambda_WLLS[2])\n",
    "\n",
    "\t\t\t\th = calculate_h_vector(Lambda_WLLS)\n",
    "\t\t\t\tK = calculate_K_matrix(Lambda_WLLS)\n",
    "\t\t\t\tPhi = calculate_Phi_matrix(K, AI, CI)\n",
    "\t\t\t\tG = calculate_G_matrix()\n",
    "\t\t\t\tz = calculate_z_vector(G, Phi, h)\n",
    "\t\t\t\t\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"AI matrix\"] = AI\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"bI vector\"] = bI\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"CI matrix\"] = CI\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Lambda_WLLS matrix\"] = Lambda_WLLS\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"G matrix\"] = G\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"K matrix\"] = K\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"h vector\"] = h\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Phi matrix\"] = Phi\n",
    "\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"z vector\"] = z\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Target Coordinates\"] = calculate_TS_WLLS_I_output(Lambda_WLLS, z)\n",
    "\t\t\t\texcept ValueError:\n",
    "\t\t\t\t\tprint(scenario_name, type, tech, c)\n",
    "\t\t\t\t\tprint(\"Error during the implementation of TS_WLLS_I.\")\n",
    "\t\t\t\t\tprint(\"There are negative values in the 'z' vector.\")\n",
    "\t\t\t\t\tprint()\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\tdataset[scenario_name][type][tech] = dict[tech]\n",
    "\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"OS_WLLS_I\"] = {}\n",
    "data[\"OS_WLLS_I\"].update(apply_OS_WLLS_I_estimator(\"Scenario A\"))\n",
    "data[\"OS_WLLS_I\"].update(apply_OS_WLLS_I_estimator(\"Scenario B\"))\n",
    "data[\"OS_WLLS_I\"].update(apply_OS_WLLS_I_estimator(\"Scenario C\"))\n",
    "\n",
    "data[\"TS_WLLS_I\"] = {}\n",
    "data[\"TS_WLLS_I\"].update(apply_TS_WLLS_I_estimator(\"Scenario A\"))\n",
    "data[\"TS_WLLS_I\"].update(apply_TS_WLLS_I_estimator(\"Scenario B\"))\n",
    "data[\"TS_WLLS_I\"].update(apply_TS_WLLS_I_estimator(\"Scenario C\"))\n",
    "\n",
    "# np.set_printoptions(suppress=True)\n",
    "# pprint.pprint(data[\"TS_WLLS_I\"])\n",
    "# for configuration in data[\"Scenario A\"][\"RPI\"][\"RSS_BLT_Dataset\"][\"Estimated\"].values():\n",
    "#     pprint.pprint(configuration[\"Target Coordinates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in data.keys():\n",
    "    estimator_dict = data[estimator]\n",
    "    for scenario in estimator_dict:\n",
    "        print(\"RMSE per\", scenario, \"-\", estimator)\n",
    "        for type in estimator_dict[scenario]:\n",
    "            for tech in estimator_dict[scenario][type]:\n",
    "                label = type + \"_\" + tech + \":\"\n",
    "                try:\n",
    "                    print(label, auxfunc.calculate_rmse(estimator_dict[scenario][type][tech]), \"m\")\n",
    "                except KeyError:\n",
    "                    print(label, \"'Target Coordinates' key not found\")\n",
    "                    break\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in data.keys():\n",
    "    auxfunc.plot_data(estimator, data[estimator])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
