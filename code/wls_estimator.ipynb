{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wls_estimator.ipynb\n",
    "- Siep Dokter\n",
    "- Emil Jousimaa\n",
    "- Oleksandr Sosovskyy\n",
    "- Mario Gabriele Carofano\n",
    "\n",
    "> This file contains the implementation of a WLS estimator, as requested in the 3rd task, used for estimate the Target Coordinates starting from the RSS information coming from the anchors.\n",
    "\n",
    "> In addition, at the end of file, there are also plots showing the actual position of the target and the anchors, and the estimated position of the target obtained from the execution of the WLS estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import import_ipynb\n",
    "import constants\n",
    "import auxfunc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_anchors_distance(anchor_dataframe):\n",
    "\t\"\"\"\n",
    "\tCalculates the distance between the target and the anchors using the Euclidean norm.\n",
    "\tThis is the implementation of (1) on the reference paper.\n",
    "\n",
    "\tParameters:\n",
    "\tanchor_dataframe (DataFrame): A DataFrame-object containing the dataset of one anchor.\n",
    "\n",
    "\tReturns:\n",
    "\ttarget_anchors_distance (list): Returns a list of distances between the target and the anchor.\n",
    "\t\"\"\"\n",
    "\n",
    "\tanchor_coords = [eval(i) for i in anchor_dataframe[\"Relative Coordinates [m]\"][0].split(\", \")]\n",
    "\ttarget_coords = [eval(i) for i in anchor_dataframe[\"Target Coordinates [m]\"][0].split(\", \")]\n",
    "\ttarget_anchors_distance = math.dist(anchor_coords, target_coords)\n",
    "\n",
    "\treturn target_anchors_distance\n",
    "\n",
    "# https://www.w3schools.com/python/ref_math_dist.asp\n",
    "# https://www.w3schools.com/python/ref_string_split.asp\n",
    "# https://www.geeksforgeeks.org/python-converting-all-strings-in-list-to-integers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_A_matrix(n_anchors, local_anchor_coords):\n",
    "\t'''\n",
    "\tCalculates the 'A' matrix of the system of equations which the WLS method solves.\n",
    "\tThis is the implementation of (5) on the reference paper.\n",
    "\n",
    "\tParameters:\n",
    "\tn_anchors (int) : An integer which value represents the number of anchors in dataset.\n",
    "\tlocal_anchor_coords (list) : A list containing one list for each anchor, e.g. the 2D-coordinates of each anchor.\n",
    "\n",
    "\tReturns:\n",
    "\tA (numpy.ndarray) : Returns a 2D numpy.ndarray which values are elements of the 'A' matrix for the selected scenario.\n",
    "\t'''\n",
    "\n",
    "\t# Build matrix A\n",
    "\tA = np.zeros((n_anchors, 3)) # 3 columns for -2x, -2y, 1\n",
    "\n",
    "\tfor i in range(n_anchors):\n",
    "\t\tA[i, 0] = -2 * local_anchor_coords[i][0]\n",
    "\t\tA[i, 1] = -2 * local_anchor_coords[i][1]\n",
    "\t\tA[i, 2] = 1\n",
    "\n",
    "\treturn A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_b_vector(n_anchors, local_anchor_coords, local_estimated_distances):\n",
    "\t'''\n",
    "\tCalculates the 'b' vector of the system of equations which the WLS method solves.\n",
    "\tThis is the implementation of (5) on the reference paper.\n",
    "\n",
    "\tParameters:\n",
    "\tn_anchors (int) : An integer which value represents the number of anchors in dataset.\n",
    "\tlocal_anchor_coords (list) : A list containing one list for each anchor, e.g. the 2D-coordinates of each anchor.\n",
    "\tlocal_estimated_distances (list):\n",
    "\tA list containing one real number for each anchor,\n",
    "\te.g. the distance estimation between each anchor and the target.\n",
    "\n",
    "\tReturns:\n",
    "\tb (numpy.ndarray): Returns a 1D numpy.ndarray which values are elements of the 'b' vector for the selected configuration.\n",
    "\t'''\n",
    "\t\n",
    "\tnorm_coords = []\n",
    "\tb = []\n",
    "\n",
    "\tfor i in range(n_anchors):\n",
    "\t\tsqr_distance = math.pow(local_estimated_distances[i], 2)\n",
    "\t\tnorm_coords.append(np.linalg.norm(local_anchor_coords))\n",
    "\t\tsqr_coords = math.pow(norm_coords[i], 2)\n",
    "\t\tdiff = sqr_distance - sqr_coords\n",
    "\t\tb.append(round(diff, 3))\n",
    "\t\ti = i + 1\n",
    "\t\n",
    "\treturn np.array(b)\n",
    "\n",
    "# https://www.digitalocean.com/community/tutorials/norm-of-vector-python\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.append.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_W_matrix(n_anchors, local_estimated_distances):\n",
    "\t\"\"\"\n",
    "\tCalculates, for the selected configuration, the 'W' diagonal matrix.\n",
    "\tThe elements are the inverse of the variance of the square of the estimated distance.\n",
    "\tThis is the implementation of [11, eq. (14)].\n",
    "\n",
    "\tParameters:\n",
    "\tn_anchors (int) : An integer which value represents the number of anchors in dataset.\n",
    "\tlocal_estimated_distances (list):\n",
    "\tA list containing one real number for each anchor,\n",
    "\te.g. the distance estimation between each anchor and the target.\n",
    "\n",
    "\tReturns:\n",
    "\tW (numpy.ndarray): Returns a 2D numpy.ndarray which values are elements of the 'W' diagonal matrix for the selected configuration.\n",
    "\t\"\"\"\n",
    "\n",
    "\tnum = math.pow(constants.STANDARD_DEVIATION, 2)\n",
    "\tden = 4.715 * math.pow(constants.PATH_LOSS_EXPONENT, 2)\n",
    "\texp_value = math.exp(num/den)\n",
    "\tvar_inverse = []\n",
    "\n",
    "\tfor i in range(n_anchors):\n",
    "\t\te4_distance = math.pow(local_estimated_distances[i], 4)\n",
    "\t\tvar = e4_distance * exp_value * (exp_value-1)\n",
    "\t\tvar_inverse.append(round(math.pow(var, -1), 3))\n",
    "\n",
    "\treturn np.diag(var_inverse)\n",
    "\t\n",
    "# https://www.w3schools.com/python/ref_math_exp.asp\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.diag.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WLS_output(A, W, b):\n",
    "\t\"\"\"\n",
    "\tCalculate the Weighted Least Squares (WLS) position estimate.\n",
    "\tThis is the implementation of (6) on the reference paper.\n",
    "\n",
    "\tParameters:\n",
    "\tA (numpy.ndarray): Matrix A.\n",
    "\tW (numpy.ndarray): Weight matrix W.\n",
    "\tb (numpy.ndarray): Vector b.\n",
    "\n",
    "\tReturns:\n",
    "\tposition (numpy.ndarray): WLS position estimate.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tA_transpose = np.transpose(A)\n",
    "\t\n",
    "\t# Calculate (A^T * W * A)^(-1) * A^T * W * b\n",
    "\tleft_term = np.linalg.inv(np.matmul(np.matmul(A_transpose, W), A))\n",
    "\tright_term = np.matmul(np.matmul(A_transpose, W), b)\n",
    "\n",
    "\t# Calculate the final result\n",
    "\tposition = np.matmul(left_term, right_term)\n",
    "\n",
    "\treturn position\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.matmul.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_WLS_estimator(scenario_name):\n",
    "\t'''\n",
    "\tApplies the WLS estimator in order to estimate the target's position\n",
    "\tfrom the anchors' position for the selected scenario.\n",
    "\n",
    "\tParameters:\n",
    "\tscenario_name (str): The name of the scenario to be examined.\n",
    "\n",
    "\tReturns:\n",
    "\tdata (dict):\n",
    "\tIt is a dictionary containing all the salient information retrieved\n",
    "\tfrom the reading of the dataset (Actual) and from the application of the WLS estimator (Estimated),\n",
    "\tfor all types of devices (Arduino, RPI) and for all technology (WiFi, BLT, Hybrid).\n",
    "\t'''\n",
    "\t\n",
    "\tdataset = auxfunc.define_dataset(scenario_name)\n",
    "\n",
    "\tfor type in dataset[scenario_name]:\n",
    "\n",
    "\t\tdict = dataset[scenario_name][type]\n",
    "\t\ttype_path = constants.DATASET_DIRECTORY + scenario_name + \"/\" + type + \"/\"\n",
    "\n",
    "\t\tfor tech in dict:\n",
    "\t\t\tdataframes = []\n",
    "\t\t\tif tech != constants.HYBRID_TECHNOLOGY:\n",
    "\t\t\t\tfor a in dict[tech][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + tech + \"/\" + a\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Concatenates the blt and wifi estimations\n",
    "\t\t\t\tfor b in dict[constants.BLT_TECHNOLOGY][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + constants.BLT_TECHNOLOGY + \"/\" + b\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\n",
    "\t\t\t\tfor w in dict[constants.WIFI_TECHNOLOGY][\"Actual\"][\"Anchors' Name\"]:\n",
    "\t\t\t\t\tanchor_path = type_path + constants.WIFI_TECHNOLOGY + \"/\" + w\n",
    "\t\t\t\t\tdataframes.append(pd.read_csv(\n",
    "\t\t\t\t\t\tanchor_path,\n",
    "\t\t\t\t\t\tsep=constants.CSV_FIELDS_SEPARATOR\n",
    "\t\t\t\t\t))\n",
    "\t\t\t\n",
    "\t\t\tdict[tech][\"Actual\"][\"Dataframes\"] = dataframes\n",
    "\n",
    "\t\tfor tech in dict:\n",
    "\t\t\tdataframes = dict[tech][\"Actual\"][\"Dataframes\"]\n",
    "\t\t\tlength = auxfunc.calculate_smallest_dataset(dataframes)\n",
    "\t\t\tburst_quantity = auxfunc.calculate_burst_quantity(length)\n",
    "\t\t\tn_anchors = len(dict[tech][\"Actual\"][\"Anchors' Name\"])\n",
    "\n",
    "\t\t\t# print(type, tech, length, burst_quantity, n_anchors, len(dataframes))\n",
    "\n",
    "\t\t\tdict[tech][\"Actual\"][\"Distance Target - Anchor\"] = []\n",
    "\t\t\tdict[tech][\"Actual\"][\"Anchor Coordinates\"] = []\n",
    "\t\t\tfor a in range(n_anchors):\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Distance Target - Anchor\"].append(dataframes[a][\"Distance Target - Anchor [m]\"][0])\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Target Coordinates\"] = [eval(i) for i in dataframes[a][\"Target Coordinates [m]\"][0].split(\", \")]\n",
    "\t\t\t\tdict[tech][\"Actual\"][\"Anchor Coordinates\"].append([eval(i) for i in dataframes[a][\"Relative Coordinates [m]\"][0].split(\", \")])\n",
    "\n",
    "\t\t\tfor c in range(burst_quantity):\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c] = {}\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Average RSS\"] = []\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"] = []\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor a in range(n_anchors):\n",
    "\t\t\t\t\taverage_RSS = auxfunc.calculate_average_RSS(dataframes[a][\"Rx Power [dBm]\"].to_list(), c, length)\n",
    "\t\t\t\t\testimated_distance = auxfunc.calculate_target_anchor_estimation(average_RSS)\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Average RSS\"].append(average_RSS)\n",
    "\t\t\t\t\tdict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"].append(estimated_distance)\n",
    "\n",
    "\t\t\t\tA_mat = calculate_A_matrix(n_anchors, dict[tech][\"Actual\"][\"Anchor Coordinates\"])\n",
    "\t\t\t\tB_vet = calculate_b_vector(n_anchors, dict[tech][\"Actual\"][\"Anchor Coordinates\"], dict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"])\n",
    "\t\t\t\tW_mat = calculate_W_matrix(n_anchors, dict[tech][\"Estimated\"][c][\"Distance Target - Anchor\"])\n",
    "\t\t\t\t\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"A matrix\"] = A_mat\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"b vector\"] = B_vet\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"W matrix\"] = W_mat\n",
    "\t\t\t\tdict[tech][\"Estimated\"][c][\"Target Coordinates\"] = calculate_WLS_output(A_mat, W_mat, B_vet)[[0,1]]\n",
    "\t\t\t\n",
    "\t\t\tdataset[scenario_name][type][tech] = dict[tech]\n",
    "\n",
    "\treturn dataset\n",
    "\t\n",
    "# https://stackoverflow.com/questions/9777783/suppress-scientific-notation-in-numpy-when-creating-array-from-nested-list\n",
    "# https://stackoverflow.com/questions/8386675/extracting-specific-columns-in-numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data.update(apply_WLS_estimator(\"Scenario A\"))\n",
    "data.update(apply_WLS_estimator(\"Scenario B\"))\n",
    "data.update(apply_WLS_estimator(\"Scenario C\"))\n",
    "\n",
    "# np.set_printoptions(suppress=True)\n",
    "# pprint.pprint(data)\n",
    "# for configuration in data[\"Scenario A\"][\"RPI\"][\"RSS_BLT_Dataset\"][\"Estimated\"].values():\n",
    "#     pprint.pprint(configuration[\"Target Coordinates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in data:\n",
    "    print(\"RMSE per\", scenario)\n",
    "    for type in data[scenario]:\n",
    "        for tech in data[scenario][type]:\n",
    "            print(type + \"_\" + tech + \":\", auxfunc.calculate_rmse(data[scenario][type][tech]), \"m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxfunc.plot_data(\"WLS\", data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9de1696fcdaf364179ab690f77d22ede36360c9c19fea9a1e8c11e7d63264b22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
